dat = read.csv('~/Desktop/nature_disruption_open_access/data/analytical/wos_cdindex_normalized_analytical_df.csv')
head(dat)
tail(dat)
clif = readxl::read_xlsx('~/Documents/Research/arcadia-clifton/clifton_1.xlsx')
clif = as.data.frame(clif)
clif[is.na(clif)] = 0
rownames(clif) = clif[,1]
clif = clif[,2:ncol(clif)]
clif2 = readxl::read_xlsx('~/Documents/Research/arcadia-clifton/clifton_3.xlsx', )
clif2 = as.data.frame(clif2)
rownames(clif2) = clif2[,1]
clif2 = clif2[,2:ncol(clif2)]
clif2 = (clif2-30)*-1
clif2[is.na(clif2)] = 0
mat = clif+clif2
pca = prcomp(mat, scale = TRUE)
biplot(pca)
plot(pca$x[,1:2])
u = umap(mat)
hcl = hclust(dist(mat))
plot(hcl)
install.packages("umao")
install.packages("umap")
install.packages("umap")
library(umap)
u = umap(mat)
plot(u$layout)
text(u$layout, labels = rownames(u$layout))
u = umap(mat)
plot(u$layout, type = 'n')
text(u$layout, labels = rownames(u$layout))
install.packages("tidytext")
library(tidytext)
install.packages("tm")
install.packages("proxy")
install.packages("dplyr")
doc = read.delim('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt')
doc = read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt')
doc
doc = unlist(read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt'))
doc
doc = unlist(as.data.frame(read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt')))
doc
doc[1,]
doc = unlist(as.data.frame(read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt'))[,1])
doc[,1]
unlist(doc[,1])
as.character(doc[,1])
as.character(as.data.frame(doc[,1]))
doc = read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome1.txt')
doc_corpus <- Corpus(VectorSource(doc))
library(tm)
library(proxy)
library(dplyr)
doc_corpus <- Corpus(VectorSource(doc))
doc_corpus
control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE)
tdm <- TermDocumentMatrix(doc_corpus, control = control_list)
tdm
tf <- as.matrix(tdm)
tf
idf <- log( ncol(tf) / ( 1 + rowSums(tf != 0) ) )
idf
idf <- diag(idf)
tf_idf <- crossprod(tf, idf)
colnames(tf_idf) <- rownames(tf)
tf_idf
tf_idf / sqrt( rowSums( tf_idfÂ² ) )
tf_idf
tf_idf / sqrt( rowSums( tf_idf^2 ) )
hist(tf_idf / sqrt( rowSums( tf_idf^2 ) ))
barplot(tf_idf / sqrt( rowSums( tf_idf^2 ) ))
barplot(tf_idf / sqrt( rowSums( tf_idf^2 ) ), las = 2)
sort(tf_idf)
tf_idf[order(tf_idf)]
tf_idf
unlist(tf_idf)
sort(unlist(tf_idf))
names(tf_idf[order(tf_idf)])
names(tf_idf)[order(tf_idf)]
names(tf_idf)
tf_idf[1]
as.numeric(tf_idf)
idf
tf
colnames(tf_idf)
colnames(tf_idf)[order(tf_idf)]
#Extract cross product
tf_idf <- crossprod(tf, idf)
#Add column names
colnames(tf_idf) <- rownames(tf)
names(tf_idf) = rownames(tf)
tf_idf
tf_idf <- unlist(crossprod(tf, idf))
tf_idf
names(tf_idf) = rownames(tf)
tf_idf
tf_idf <- crossprod(tf, idf)
tf_idf = unlist(tf_idf[1,])
tf_idf
names(tf_idf) = rownames(tf)
sort(tf_idf)
doc = read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc
doc = read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc = readLines('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc
doc = readLines('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc = as.character(as.data.frame(doc[,1]))
#Load
doc = readLines('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc = unlist(doc)
doc
doc[1]
doc[2]
doc[3]
#Load
doc = readLines('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc = unlist(doc)
#Create corpus
doc_corpus <- Corpus(VectorSource(doc))
#Generate TDM
control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE)
tdm <- TermDocumentMatrix(doc_corpus, control = control_list)
#Generate TF
tf <- as.matrix(tdm)
#Generate IDF
idf <- log( ncol(tf) / ( 1 + rowSums(tf != 0) ) )
#Extract diagonal
idf <- diag(idf)
#Extract cross product
tf_idf <- crossprod(tf, idf)
tf_idf = unlist(tf_idf[1,])
#Add column names
names(tf_idf) = rownames(tf)
#Calculate ratio
tf_idf = tf_idf / sqrt( rowSums( tf_idf^2 ) )
doc = readLines('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome2.txt')
doc = as.character(doc)
doc_corpus <- Corpus(VectorSource(doc))
#Generate TDM
control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE)
tdm <- TermDocumentMatrix(doc_corpus, control = control_list)
#Generate TF
tf <- as.matrix(tdm)
#Generate IDF
idf <- log( ncol(tf) / ( 1 + rowSums(tf != 0) ) )
#Extract diagonal
idf <- diag(idf)
#Extract cross product
tf_idf <- crossprod(tf, idf)
tf_idf = unlist(tf_idf[1,])
#Add column names
names(tf_idf) = rownames(tf)
#Calculate ratio
tf_idf = tf_idf / sqrt( rowSums( tf_idf^2 ) )
doc = read.table('~/Desktop/science-semantic-tracing/00_data/chatgpt/genome3.txt')
doc
clif = readxl::read_xlsx('~/Documents/Research/arcadia-clifton/clifton_1.xlsx')
clif = as.data.frame(clif)
clif[is.na(clif)] = 0
rownames(clif) = clif[,1]
clif = clif[,2:ncol(clif)]
mat = clif
u = umap(mat)
plot(u$layout, type = 'n')
text(u$layout, labels = rownames(u$layout))
hcl = hclust(dist(mat))
plot(hcl)
pca = prcomp(mat, scale = TRUE)
biplot(pca)
u = umap(mat)
plot(u$layout, type = 'n')
text(u$layout, labels = rownames(u$layout))
IRkernel::installspec()
IRkernel::installspec(user = FALSE)
##TO DO:
#All by all comparisons between species using binned phylogenetic signal -> compare distance between species as a function of tree time (x vs y)
#Calculate phylogenetic signal using windows of each spectra e.g. 50 wavenumbers per window (can do both mean per window and/or pca on each window)
#Try removing S. agalactiae
#Plot phylosig via spectra alongside mean species traces
#Set working directory
setwd('/Users/ryanyork/Documents/Research/github/raman-taxonomy/')
#Source utilities
source('01_utils/R/raman-taxonomy-utils.R')
#Load Ho et al. 2019 data
x = np$load('00_data/ho_et_al_2019/X_finetune.npy')
y = np$load('00_data/ho_et_al_2019/y_finetune.npy')
#Reverse
x = x[,ncol(x):1]
#Load config (contains strain name info, etc.)
config = source_python('00_data/ho_et_al_2019/config.py')
#Get names by ordering strains (have to +1 order since its 0 indexed as in python; R wants to start with 1)
n = unlist(STRAINS)
#Load taxonomic groups
taxa = read.csv('00_data/ho_et_al_2019/taxonomic_groups.csv')
#Load wavenumbers
wav = rev(np$load('00_data/ho_et_al_2019/wavenumbers.npy'))
#Calculate strain means
m = lapply(split(as.data.frame(x), y), function(z) colMeans(z))
m = do.call(rbind, m)
rownames(m) = n
#Calculate strain standard error
se = lapply(split(as.data.frame(x), y), function(z){
apply(z, 2, function(w) plotrix::std.error(w))
})
se = do.call(rbind, se)
rownames(se) = n
#Save
#Load phylogeny
phylo = read.newick('00_data/ho_et_al_2019/ho_2019_species_list_for_timetree.nwk')
phylo = drop.tip(phylo, 'Streptococcus_agalactiae')
#Generate matrix for calculate means by species
m2 = m
rownames(m2) = paste(taxa$Genus, taxa$Species, sep = '_')
#Split by species
m2 = split(as.data.frame(m2), rownames(m2))
#Calculate mean by species
m2 = lapply(m2, function(x) colMeans(x))
#Recombine
m2 = do.call(rbind, m2)
m2 = m2[!rownames(m2) == 'Streptococcus_agalactiae',]
#Generate phylogeny from spectra
spectra = as.phylo(nj(dist(m2)))
pca = prcomp(m2)
#Phylogenetic signal of PCs
phylosig_pcs = apply(pca$x[match(phylo$tip.label, rownames(pca$x)),], 2, function(x) phylosig(phylo, x, method = 'lambda')[1]$lambda)
#Phylogenetic signal of spectra
phylosig_spectra = apply(m2[match(phylo$tip.label, rownames(m2)),], 2, function(x) phylosig(phylo, x, method = 'lambda')[1]$lambda)
phylosig_spectra_k = apply(m2[match(phylo$tip.label, rownames(m2)),], 2, function(x) phylosig(phylo, x, method = 'K')[1])
#By windows
len = 25
win = split_with_overlap(t(m2), len, len-1)[1:(ncol(m2)-len)]
win_phy = list()
for(i in 1:length(win)){
p = prcomp(t(win[[i]]))
p = p$x[match(phylo$tip.label, rownames(p$x)),2]
mn = colMeans(win[[i]])
mn = phylosig(phylo, mn, method = 'lambda')[1]$lambda
p = phylosig(phylo, p, method = 'lambda')[1]$lambda
l = list(mn, p)
names(l) = c('mean', 'pca')
win_phy[[as.character(i)]] = l
}
pc = unlist(lapply(win_phy, function(x) x$pca))
mn = unlist(lapply(win_phy, function(x) x$mean))
#Find peaks in window-based phylogenetic signal
a = which(mn>0.01)
idx <- c(0, cumsum(abs(diff(a)) > 2))
indices = split(a, idx)
split(m2,cumsum(a>0.01))
idx
split(m2,indices)
indices$0
indices[[1]]
mean(unlist(lapply(indices, function(x) length(x))))
mean(unlist(lapply(indices, function(x) sd(x))))
sd(unlist(lapply(indices, function(x) length(x))))
m2
mn
split(mn, indices)
idx
bands = split(mn, idx)
bands
lapply(bands, function(x) max(x))
sort(unlist(lapply(bands, function(x) max(x))))
#Tree variation as a function of time
len = 25
win = split_with_overlap(t(m2), len, len-1)[1:(ncol(m2)-len)]
win_times = list()
for(i in 1:length(indices)){
res = list()
d = as.matrix(dist(m2[,min(indices[[i]]):max(indices[[i]])]))
d = as.data.frame(as.table(d))
for(j in 0:round(max(p$Freq))){
#Filter on cophenetic distances
z = d[which(p$Freq>=j),]
#Remove self comparisons
z = z[!z[,1] == z[,2],]
#Add to list
res[[as.character(j)]] = z
}
#Calculate mean
p_mean = unlist(lapply(res, function(x) mean(x$Freq)))
#plot(p_mean, type = 'l')
win_times[[as.character(i)]] = p_mean
}
len = 25
win = split_with_overlap(t(m2), len, len-1)[1:(ncol(m2)-len)]
win_cosine = list()
for(i in 1:length(win)){
p = as.matrix(dist(t(win[[i]])))
win_cosine[[as.character(i)]] = unlist(as.data.frame(p))
}
win_cosine = do.call(cbind, win_cosine)
#Sort by divergence time
p = as.matrix(dist(t(win[[1]])))
p = as.data.frame(as.table(p))
z = as.matrix(dist(t(cophen)))
p
p$Freq
z
#Calculate cophenic distances
cophen = cophenetic.phylo(phylo)
#Get max divergence times for each taxonomic grouping
times = matrix(ncol = 4)
for(i in 1:nrow(cophen)){
for(j in 1:ncol(cophen)){
x = taxa2[grep(rownames(cophen)[i],
paste(taxa2$Genus, taxa2$Species, sep = '_')),][1,]
y = taxa2[grep(rownames(cophen)[j],
paste(taxa2$Genus, taxa2$Species, sep = '_')),][1,]
z = names(x)[max(which(x%in%y==FALSE))]
times = rbind(times, cbind(z, rownames(cophen)[i], colnames(cophen)[j], as.numeric(cophen[i,j])))
}
}
cophen = as.data.frame(as.table(cophen))
#Sort by divergence time
p = as.matrix(dist(t(win[[1]])))
p = as.data.frame(as.table(p))
z = as.matrix(dist(t(cophen)))
z = as.data.frame(as.table(z))
a = max(z$Freq)/max(phylo$edge.length)
z$Freq = z$Freq/a
p = p[match(paste(z[,1], z[,2]), paste(p[,1], p[,2])),]
p$Freq = z$Freq
z
cophen = cophenetic.phylo(phylo)
#Sort by divergence time
p = as.matrix(dist(t(win[[1]])))
p = as.data.frame(as.table(p))
z = as.matrix(dist(t(cophen)))
z = as.data.frame(as.table(z))
a = max(z$Freq)/max(phylo$edge.length)
z$Freq = z$Freq/a
p = p[match(paste(z[,1], z[,2]), paste(p[,1], p[,2])),]
p$Freq = z$Freq
p
z
#Tree variation as a function of time
len = 25
win = split_with_overlap(t(m2), len, len-1)[1:(ncol(m2)-len)]
win_times = list()
for(i in 1:length(indices)){
res = list()
d = as.matrix(dist(m2[,min(indices[[i]]):max(indices[[i]])]))
d = as.data.frame(as.table(d))
for(j in 0:round(max(p$Freq))){
#Filter on cophenetic distances
z = d[which(p$Freq>=j),]
#Remove self comparisons
z = z[!z[,1] == z[,2],]
#Add to list
res[[as.character(j)]] = z
}
#Calculate mean
p_mean = unlist(lapply(res, function(x) mean(x$Freq)))
#plot(p_mean, type = 'l')
win_times[[as.character(i)]] = p_mean
}
#Non conserved windows
len = 25
win = split_with_overlap(t(m2), len, len-1)[1:(ncol(m2)-len)]
non = list()
for(i in 1:length(indices)){
res = list()
d = as.matrix(dist(m2[,(max(indices[[i]])+1):min(indices[[i+1]]-1)]))
d = as.data.frame(as.table(d))
for(j in 0:round(max(p$Freq))){
#Filter on cophenetic distances
z = d[which(p$Freq>=j),]
#Remove self comparisons
z = z[!z[,1] == z[,2],]
#Add to list
res[[as.character(j)]] = z
}
#Calculate mean
p_mean = unlist(lapply(res, function(x) mean(x$Freq)))
#plot(p_mean, type = 'l')
non[[as.character(i)]] = p_mean
}
win_times
lapply(win_times, function(x) which.max(x))
win_cosine
plot(win_times[[1]])
lapply(win_times, function(x) which.max(x))
hist(unlist(lapply(win_times, function(x) which.max(x))))
plot(lapply(win_times, function(x) which.max(x)))
plot(unlist(lapply(win_times, function(x) which.max(x))))
plot(unlist(lapply(non, function(x) which.max(x))))
plot(unlist(lapply(win_times, function(x) mean(x))))
plot(unlist(lapply(win_times, function(x) mean(x, na.rm = TRUE))))
w = unlist(lapply(win_times, function(x) mean(x, na.rm = TRUE)))
n = unlist(lapply(non, function(x) mean(x, na.rm = TRUE)))
w
n
mean(w)
mean(n)
kruskal.test(w, n)
kruskal.test(list(w, n))
w = unlist(lapply(win_times, function(x) median(x, na.rm = TRUE)))
n = unlist(lapply(non, function(x) median(x, na.rm = TRUE)))
kruskal.test(list(w, n))
w
n
w = unlist(lapply(win_times, function(x) which.max(x, na.rm = TRUE)))
w = unlist(lapply(win_times, function(x) which.max(x)))
n = unlist(lapply(non, function(x) which.max(x)))
kruskal.test(list(w, n))
size = as.data.frame(read.csv('00_data/ho_et_al_2019/ho_2019_expanded_genome_statistics.csv'))
size = as.data.frame(apply(size, 2, function(x) gsub('\\,', '', x)))
#Calculate pca
pca = prcomp(m2)
#Match genome size matrix to order of spectral data
size = size[match(rownames(pca$x), gsub(' ', '_', size$Genome)),]
#Remove 'Streptococcus_agalactiae'
size = size[!size$Genome == 'Streptococcus agalactiae',]
#Linear model
#summary(lm(pca$x[,1]~size$media_gc_content+size$median_genome_size+size$median_protein_count))
apply(size[,2:ncol(size)], 2, function(x) cor(as.numeric(x), as.numeric(pca$x[,1]), use = 'complete.obs'))
#Linear models by window
len = 25
mods = list()
for(i in 1:(ncol(m2)-len)){
d = m2[,i:(i+len)]
pca = prcomp(d)
o = apply(size[,2:ncol(size)], 2, function(x) summary(lm(pca$x[,1]~as.numeric(x)))[9])
mods[[as.character(i)]] = o
}
cors = c()
for(i in 1:length(mods[[1]])){
cors = c(cors, cor(mn, unlist(lapply(mods, function(x) x[i]))))
}
names(cors) = names(mods[[1]])
cors
cor.test(mn, unlist(lapply(mods, function(x) x[1])))
tmp = cor.test(mn, unlist(lapply(mods, function(x) x[1])))
tmp$p.value
cors = c()
for(i in 1:length(mods[[1]])){
cors = c(cors, cor(mn, unlist(lapply(mods, function(x) x[i])))$p.value)
}
cors
cors = c()
for(i in 1:length(mods[[1]])){
cors = c(cors, cor.test(mn, unlist(lapply(mods, function(x) x[i])))$p.value)
}
cors
pred = as.data.frame(cbind())
mod = lm(mn~unlist(lapply(mods, function(x) x$Size..Mb.))+unlist(lapply(mods, function(x) x$GC.))+unlist(lapply(mods, function(x) x$Protein))+
unlist(lapply(mods, function(x) x$rRNA))+unlist(lapply(mods, function(x) x$tRNA))+unlist(lapply(mods, function(x) x$Other.RNA))+
unlist(lapply(mods, function(x) x$Gene))+unlist(lapply(mods, function(x) x$Pseudogene)))
mod
summary(mod)
summary(mod)[4]
summary(mod)[5]
summary(mod)[6]
summary(mod)[7]
summary(mod)[8]
summary(mod)[9]
summary(mod)[10]
summary(mod)[11]
summary(mod)[12]
summary(mod)[13]
summary(mod)[3]
summary(mod)[2]
install.packages()
install.packages('here')
install.packages("here")
?here
install.packages("gkgraphR")
library(gkgraphR)
query_apple <- querygkg(query = "apple", api.key = {YOUR_API_KEY}) # Replace YOUR_API_KEY with a valid Google API key
query_apple <- querygkg(query = "apple", api.key = {'AIzaSyCZc5wu-TDDfGXlOY-ay2odSWi4BaUvwQg'}) # Replace YOUR_API_KEY with a valid Google API key
query_apple
query_apple <- querygkg(query = "Chlamydomonas",
api.key = {'AIzaSyCZc5wu-TDDfGXlOY-ay2odSWi4BaUvwQg'},
limit = 40)
query_apple
querygkg(query = "Chlamydomonas reinhardtii",
api.key = {'AIzaSyCZc5wu-TDDfGXlOY-ay2odSWi4BaUvwQg'},
limit = 40)
?barplot
install.packages("styler")
library(styler)
styler:::style_active_file()
